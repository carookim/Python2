{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3a25de",
   "metadata": {},
   "source": [
    "#### 로지스틱회귀 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 불러오기 : 기존 수치형 데이터\n",
    "# import pandas as pd\n",
    "# path = \"C:\\\\Users\\\\Playdata2\\\\Downloads\\\\regression_model_preprocessed.csv\"\n",
    "# df = pd.read_csv(path)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f13a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 : 로그 변환 수치형 데이터\n",
    "import pandas as pd\n",
    "path = \"C:\\\\Users\\\\Playdata2\\\\Downloads\\\\re_log_model_preprocessed.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80454f13",
   "metadata": {},
   "source": [
    "#### LogisticRegression Basic\n",
    "- 하이퍼파라미터 지정 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 데이터 분리 (X: feature, y: target)\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 모델 생성 및 학습\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# 3. 예측\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# 4. 성능 조회\n",
    "print(f\"\\n=== LogisticRegression ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 수치형 데이터 : LogisticRegression (기본값 - 하이퍼파리미터 지정 X)\n",
    "# === LogisticRegression ===\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.89      0.94      0.91      6327\n",
    "#            1       0.95      0.91      0.93      8052\n",
    "\n",
    "#     accuracy                           0.92     14379\n",
    "#    macro avg       0.92      0.92      0.92     14379\n",
    "# weighted avg       0.92      0.92      0.92     14379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 변환 수치형 데이터 : LogisticRegression (기본값 - 하이퍼파리미터 지정 X)\n",
    "# === LogisticRegression ===\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.91      0.94      0.93      6327\n",
    "#            1       0.95      0.93      0.94      8052\n",
    "\n",
    "#     accuracy                           0.93     14379\n",
    "#    macro avg       0.93      0.93      0.93     14379\n",
    "# weighted avg       0.93      0.93      0.93     14379"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d88bbc",
   "metadata": {},
   "source": [
    "#### LogisticRegression Hyperparameter\n",
    "- 하이퍼파라미터 항목 지정\n",
    "```\n",
    "StandardScaler : 되도록 원본 데이터의 크기를 너무 수정하지 않는 방향으로 스케일링하기.\n",
    "                 연속형데이터만 스케일링 고려.\n",
    "GridSearch - PolynomialFeatures - degree\n",
    "             LogisticRegression - C , max_iter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226cbd2",
   "metadata": {},
   "source": [
    "##### PolynomialFeatures, StandardScaler 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PolynomialFeatures, StandardScaler 적용\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. 데이터 분리 (X: feature, y: target)\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 파이프라인 생성\n",
    "pipeline = Pipeline([\n",
    "    ('poly',PolynomialFeatures(degree=3,include_bias=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(C=100, max_iter=1000))\n",
    "])\n",
    "\n",
    "# 4. 모델 학습\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. 예측\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== LogisticRegression ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d06b4",
   "metadata": {},
   "source": [
    "##### GridSearch 적용하여 하이퍼파라미터 최적값 찾고 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tqdm tqdm-joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression, PolynomialFeatures, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. 데이터 분리 (X: feature, y: target)\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 파이프라인 생성\n",
    "pipeline = Pipeline([\n",
    "    ('poly',PolynomialFeatures(degree=3,include_bias=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 3. 그리드 서치 파라미터 설정\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3],\n",
    "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'lr__max_iter': [500, 1000, 2000]\n",
    "}\n",
    "\n",
    "# 4. GridSearchCV 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                # 교차검증 5-fold\n",
    "    n_jobs=-1,           # 병렬 처리\n",
    "    scoring='f1',        # 분류 문제이므로 f1-score 사용 가능\n",
    "    verbose=2            # 진행현황 표시\n",
    ")\n",
    "\n",
    "# 5. 모델 학습\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 7. 최적 모델 생성 및 예측\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 8. 성능 평가\n",
    "print(\"\\n=== Logistic Regression (with GridSearch) ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20251104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression, PolynomialFeatures, StandardScaler(연속형 컬럼만), GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 데이터 분리 (X: feature, y: target)\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 연속형 컬럼만 정규화\n",
    "# 연속형 컬럼 지정\n",
    "num_cols = ['bill_avg_log', 'download_avg_log', 'upload_avg_log', 'service_failure_count']\n",
    "\n",
    "# ColumnTransformer: 지정한 컬럼만 스케일링, 나머지는 그대로 둠\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # 나머지 컬럼은 그대로\n",
    ")\n",
    "\n",
    "# 3. 파이프라인 구성\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('poly', PolynomialFeatures(include_bias=True)),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 4. 그리드 서치 파라미터 설정\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3],\n",
    "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'lr__max_iter': [500, 1000, 2000]\n",
    "}\n",
    "\n",
    "# 5. GridSearchCV 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 6. 모델 학습\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 7. 결과 출력\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 8. 최적 모델로 예측\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 9. 성능 평가\n",
    "print(\"\\n=== Logistic Regression (with selective scaling and gridsearch) ===\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
