{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.meta.com/vjepa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torchcodec==0.2.1 (from versions: 0.0.0.dev0, 0.7.0, 0.8.0, 0.8.1)\n",
      "ERROR: No matching distribution found for torchcodec==0.2.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decord\n",
      "  Downloading decord-0.6.0-py3-none-win_amd64.whl.metadata (422 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from decord) (2.3.3)\n",
      "Downloading decord-0.6.0-py3-none-win_amd64.whl (24.7 MB)\n",
      "   ---------------------------------------- 0.0/24.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/24.7 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.2/24.7 MB 46.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.3/24.7 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.7 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.7/24.7 MB 29.0 MB/s  0:00:00\n",
      "Installing collected packages: decord\n",
      "Successfully installed decord-0.6.0\n",
      "Collecting transformers==4.52.4\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from transformers==4.52.4) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.52.4)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from transformers==4.52.4) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from transformers==4.52.4) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.52.4)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.52.4)\n",
      "  Using cached regex-2025.10.23-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from transformers==4.52.4) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.52.4)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.52.4)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from transformers==4.52.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.52.4) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from requests->transformers==4.52.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from requests->transformers==4.52.4) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from requests->transformers==4.52.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from requests->transformers==4.52.4) (2025.10.5)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.5/10.5 MB 57.9 MB/s  0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 23.1 MB/s  0:00:00\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 61.8 MB/s  0:00:00\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached regex-2025.10.23-cp313-cp313-win_amd64.whl (276 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Installing collected packages: safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ------------- -------------------------- 2/6 [pyyaml]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [tokenizers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   ---------------------------------------- 6/6 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.36.0 pyyaml-6.0.3 regex-2025.10.23 safetensors-0.6.2 tokenizers-0.21.4 transformers-4.52.4\n",
      "Collecting torch==2.6.0\n",
      "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3\n",
      "ERROR: Could not find a version that satisfies the requirement torchvision==0.17.0 (from versions: 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.24.0)\n",
      "ERROR: No matching distribution found for torchvision==0.17.0\n",
      "c:\\Users\\Playdata2\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 1️⃣ 라이브러리 설치 및 환경 설정\n",
    "# ==========================================================\n",
    "\n",
    "# Hugging Face Transformers, Torchcodec, Decord 설치\n",
    "# Colab 환경에서는 !pip 사용 가능\n",
    "!pip install transformers==4.52.4\n",
    "!pip install torchcodec==0.2.1\n",
    "!pip install decord\n",
    "\n",
    "# PyTorch 설치 (GPU 사용 환경)\n",
    "!pip install torch==2.6.0 torchvision==0.17.0 torchaudio==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 2️⃣ 모델과 비디오 프로세서 로드\n",
    "# ==========================================================\n",
    "\n",
    "from transformers import AutoVideoProcessor, AutoModel\n",
    "import torch\n",
    "\n",
    "# 사전학습된 V-JEPA2 모델 이름\n",
    "hf_repo = \"facebook/vjepa2-vitl-fpc64-256\"\n",
    "\n",
    "# 모델 로드 (GPU 사용)\n",
    "model = AutoModel.from_pretrained(hf_repo).to(\"cuda\")  # GPU가 없으면 \"cpu\"로 변경\n",
    "# 비디오 전처리용 processor 로드\n",
    "processor = AutoVideoProcessor.from_pretrained(hf_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65547f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 3️⃣ 테스트용 비디오 불러오기\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import decord\n",
    "from decord import VideoReader, cpu\n",
    "\n",
    "# 테스트용 비디오 파일 경로\n",
    "video_path = \"test_video.mp4\"  # 자신의 비디오 파일 경로로 변경\n",
    "\n",
    "# 비디오 로드\n",
    "vr = VideoReader(video_path, ctx=cpu(0))\n",
    "video = vr[:].asnumpy()  # 전체 프레임을 numpy array로 변환 (shape: num_frames x H x W x 3)\n",
    "\n",
    "print(f\"비디오 프레임 개수: {video.shape[0]}\")\n",
    "print(f\"비디오 해상도: {video.shape[1]}x{video.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 4️⃣ 프레임 선택 및 전처리\n",
    "# ==========================================================\n",
    "\n",
    "# 모델 입력용으로 64개 프레임만 선택\n",
    "num_frames = 64\n",
    "frame_idx = np.linspace(0, video.shape[0]-1, num_frames).astype(int)  # 0~마지막 프레임 사이 균등 선택\n",
    "video_frames = video[frame_idx]\n",
    "\n",
    "# processor를 통해 전처리\n",
    "inputs = processor(video_frames, return_tensors=\"pt\").to(\"cuda\")  # GPU 사용\n",
    "\n",
    "print(\"입력 전처리 완료\")\n",
    "print(f\"입력 텐서 shape: {inputs['pixel_values'].shape}\")  # (1, 64, 3, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 5️⃣ 모델로 비디오 특징 추출\n",
    "# ==========================================================\n",
    "\n",
    "with torch.no_grad():  # 추론 시 gradient 계산 불필요\n",
    "    features = model.get_vision_features(**inputs)  # shape: (1, 64, 1024) 예시\n",
    "\n",
    "print(\"모델 특징 추출 완료\")\n",
    "print(f\"추출된 특징 shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefe639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 6️⃣ 다운스트림 활용 예시\n",
    "# ==========================================================\n",
    "\n",
    "# features를 사용하여 영상 검색, 분류, 클러스터링 등 가능\n",
    "# 예시: 각 프레임 평균 임베딩 계산\n",
    "video_embedding = features.mean(dim=1)\n",
    "print(f\"영상 전체 임베딩 shape: {video_embedding.shape}\")  # (1, 1024)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
