{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28221c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TensorFlow 설치\n",
    "# %pip install tensorflow\n",
    "\n",
    "# # PyTorch 설치 (기본 CPU 버전)\n",
    "# %pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f388aa2",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 불러오기 1 : 기존 수치형 데이터\n",
    "# import pandas as pd\n",
    "# url = \"C:\\\\Users\\\\Playdata2\\\\Downloads\\\\tree_model_preprocessed.csv\"\n",
    "# df = pd.read_csv(url)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 2 : 로그변환 수치형 데이터\n",
    "import pandas as pd\n",
    "url = \"C:\\\\Users\\\\Playdata2\\\\Downloads\\\\re_log_model_preprocessed.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12524c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b20b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc1da6",
   "metadata": {},
   "source": [
    "#### 스케일링 별 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82629737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 별 데이터 생성\n",
    "# 1. 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# 2. 입력(X), 타깃(y) 분리\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "# 3. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 스케일링\n",
    "# StandardScaler (기본), MinMaxScaler (정규화), RobustScaler (이상치 많을 때)\n",
    "scaler = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "\n",
    "X_train_scaled = scaler[0].fit_transform(X_train)\n",
    "X_train_MMS_scaled = scaler[1].fit_transform(X_train)\n",
    "X_train_RS_scaled = scaler[2].fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler[0].transform(X_test)\n",
    "X_test_MMS_scaled = scaler[1].transform(X_test)\n",
    "X_test_RS_scaled = scaler[2].transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca67b8",
   "metadata": {},
   "source": [
    "#### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# 평가 지표 계산 함수\n",
    "def compute_sequence_metrics(pred_orders, target_orders):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    if isinstance(pred_orders[0], list):\n",
    "        for gt, pred in zip(target_orders, pred_orders):\n",
    "            if len(gt) != len(pred):\n",
    "                continue\n",
    "            y_true.extend(gt)\n",
    "            y_pred.extend(pred)\n",
    "    else:\n",
    "        y_true = target_orders\n",
    "        y_pred = pred_orders\n",
    "\n",
    "    # Macro-average : 클래스별 성능 지표를 각각 계산 후 평균 -> 클래스별 데이터셋이 균등하게 분포되어 있을 때 적절\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "\n",
    "class Dataset_Module:\n",
    "    def __init__(self, file_name):\n",
    "        super().__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "        df = pd.read_csv(f'../data/{self.file_name}')\n",
    "        X = df.drop(columns=[\"churn\", \"remaining_contract\", \"is_tv_subscriber\", \"is_movie_package_subscriber\"], axis=1)\n",
    "        y = df['churn']\n",
    "\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X, y, random_state=42, test_size=0.2,\n",
    "                                                                              stratify=y)\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        train_dataset = Train_Dataset(self.X_train, self.y_train)\n",
    "        val_dataset = Train_Dataset(self.X_val, self.y_val)\n",
    "\n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "# PyTorch용 Dataset 정의\n",
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # getter\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data.iloc[idx].to_numpy() # Pandas Series -> Numpy 배열\n",
    "        label = self.label.iloc[idx] # int 형식의 값들 이므로 Numpy 배열 변환 X\n",
    "\n",
    "        return data, label\n",
    "\n",
    "\n",
    "\n",
    "# 다층 퍼셉트론 Multi-Layer Perceptron 신경망 정의\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, Cin):\n",
    "        super().__init__()\n",
    "        self.Cin = Cin\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(Cin, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1) # 이진분류 출력 노드 1개\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    dataset = Dataset_Module(file_name='train.csv')\n",
    "    train_dataset, val_dataset = dataset.get_train_dataset()\n",
    "\n",
    "    # 입력 특성 수 확인\n",
    "    Cin = train_dataset.__getitem__(0)[0].shape\n",
    "    print(f\"num Feature : {Cin}\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    model = MLPNet(Cin[0])\n",
    "    criterion = nn.BCEWithLogitsLoss() # 이진분류 손실함수\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.to(device)\n",
    "\n",
    "    train_epoch = 100\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # 최고 성능 기록 위한 dict\n",
    "    best_metrics = {'f1': 0, 'precision': 0, 'recall': 0, 'accuracy': 0}\n",
    "\n",
    "    for epoch in range(train_epoch):\n",
    "        # 학습\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iter = tqdm(train_loader, desc=f\"[Epoch {epoch + 1}/{train_epoch}] Training\")\n",
    "\n",
    "        for batch_data, batch_label in train_iter:\n",
    "            batch_data, batch_label = batch_data.to(device).float(), batch_label.to(device).float().unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_iter.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_label in tqdm(val_loader, desc=f\"[Epoch {epoch + 1}/{train_epoch}] Validation\"):\n",
    "                batch_data, batch_label = batch_data.to(device).float(), batch_label.to(device).float().unsqueeze(-1)\n",
    "\n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_label)\n",
    "                val_loss += loss.item()\n",
    "                outputs = F.sigmoid(outputs)\n",
    "                preds = (outputs > 0.5).float()\n",
    "\n",
    "                correct += (preds == batch_label).sum().item()\n",
    "                total += batch_label.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(batch_label.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # 평가지표 계산\n",
    "        val_f1, val_precision, val_recall = compute_sequence_metrics(all_preds, all_labels)\n",
    "\n",
    "        print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
    "        print(f\"Epoch {epoch + 1} - F1 : {val_f1:.4f}, Precision : {val_precision:.4f}, Recall : {val_recall:.4f}\")\n",
    "\n",
    "        # 최고 성능 갱신 시 모델 저장\n",
    "        if val_accuracy > best_metrics['accuracy']:\n",
    "            best_metrics['f1'] = val_f1\n",
    "            best_metrics['precision'] = val_precision\n",
    "            best_metrics['recall'] = val_recall\n",
    "            best_metrics['accuracy'] = val_accuracy\n",
    "            torch.save(model.state_dict(), '../best_model.pt')  # 모델 파라미터 저장\n",
    "\n",
    "    # 최종능 평가 지표 출력\n",
    "    print(\"\\n=== 최종 평가 지표 (Validation Best Accuracy 기준) ===\")\n",
    "    print(f\"F1 Score     : {best_metrics['f1']:.4f}\")\n",
    "    print(f\"Precision    : {best_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall       : {best_metrics['recall']:.4f}\")\n",
    "    print(f\"Accuracy (%) : {best_metrics['accuracy']:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "# === 최종 평가 지표 (Validation Best Accuracy 기준) ===\n",
    "# F1 Score     : 0.7327\n",
    "# Precision    : 0.7386\n",
    "# Recall       : 0.7308\n",
    "# Accuracy (%) : 73.95%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965e7ae",
   "metadata": {},
   "source": [
    "#### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e99c6d",
   "metadata": {},
   "source": [
    "##### 기존 수치형 데이터 와 로그변환 데이터 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ffaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 수치형 데이터 와 로그변환 데이터 비교용 모델\n",
    "# StandardScaler, layer 2, 64-32-1, relu, sigmoid, adam, binary_crossentropy\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== Log Data ===\")\n",
    "# print(f\"\\n=== Num Data ===\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그변환 모델이 0.1만큼 좋았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4392e",
   "metadata": {},
   "source": [
    "##### 레이어층 2, 뉴런조합별 성능 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64-32-1\n",
    "# StandardScaler, layer 2, 64-32-1, relu, sigmoid, adam, binary_crossentropy\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== 64-32-1 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32-16-1\n",
    "# 기존 수치형 데이터 와 로그변환 데이터 비교용 모델\n",
    "# StandardScaler, layer 2, 32-16-1, relu, sigmoid, adam, binary_crossentropy\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== 32-16-1 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16-8-1\n",
    "# 기존 수치형 데이터 와 로그변환 데이터 비교용 모델\n",
    "# StandardScaler, layer 2, 16-8-1, relu, sigmoid, adam, binary_crossentropy\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== 16-8-1 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573c00e",
   "metadata": {},
   "source": [
    "##### 레이어층 3, 뉴런조합별 성능 출력\n",
    "- 피라미드형\n",
    "- 늘렸다 줄이기\n",
    "- 줄였다 늘리기\n",
    "과적합 일어날시 Drop out을 사용하지만\n",
    "Drop out적용해서 성능 수치 올라가는 경우도 있다고 하니, Drop out사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f190a6",
   "metadata": {},
   "source": [
    "##### 피라미드형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 -> 64 -> 32 -> 1\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== 128 -> 64 -> 32 -> 1 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64  -> 32 -> 16 -> 1\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== 64-32-1 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66030946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 -> 16 -> 8 -> 1\n",
    "# 1. 모델 정의\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=2)\n",
    "\n",
    "# 4. 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\n Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 4. 예측\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# 6. 성능 조회\n",
    "print(f\"\\n=== 64-32-1 ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
